{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b683108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ROOT = C:\\Users\\Balerion\\Desktop\\us-flights-delay\n",
      "[INFO] ROOT = C:\\Users\\Balerion\\Desktop\\us-flights-delay\n",
      "[INFO] src exists?  True\n",
      "[INFO] config.yml chargé depuis : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\config.yml\n",
      "[INFO] DATA_RAW_DIR      = C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\raw\n",
      "[INFO] DATA_PROCESSED_DIR= C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\processed\n",
      "[INFO] WEATHER_DIR       = C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\weather\n",
      "[INFO] MODELS_DIR        = C:\\Users\\Balerion\\Desktop\\us-flights-delay\\models\n",
      "[INFO] REPORTS_DIR       = C:\\Users\\Balerion\\Desktop\\us-flights-delay\\reports\n",
      "[INFO] MLRUNS_DIR        = C:\\Users\\Balerion\\Desktop\\us-flights-delay\\mlruns\n",
      "[INFO] MLFLOW_TRACKING_URI (cfg) = file:///C:/Users/Balerion/Desktop/us-flights-delay/mlruns\n",
      "[INFO] MLflow experiment name    = us_flights_delay\n",
      "[INFO] HIGH_DELAY_RATE_THRESHOLD = 0.25\n",
      "[INFO] WEATHER_CACHE_DIR         = C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\weather\n",
      "[INFO] WEATHER_CACHE_FILE        = C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\weather\\weather_cache.json\n",
      "[INFO] WEATHER_DAILY_VARIABLES   = ['temperature_2m_mean', 'precipitation_sum', 'windspeed_10m_max']\n",
      "──────────────────────────\n",
      "[CONFIG] Projet : us_flights_delay\n",
      "[CONFIG] ROOT   : C:\\Users\\Balerion\\Desktop\\us-flights-delay\n",
      "[CONFIG] DATA_RAW_DIR       : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\raw\n",
      "[CONFIG] DATA_PROCESSED_DIR : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\processed\n",
      "[CONFIG] WEATHER_DIR        : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\weather\n",
      "[CONFIG] MODELS_DIR         : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\models\n",
      "[CONFIG] REPORTS_DIR        : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\reports\n",
      "[CONFIG] MLRUNS_DIR         : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\mlruns\n",
      "──────────────────────────\n",
      "[CONFIG] MLflow tracking URI : file:///C:/Users/Balerion/Desktop/us-flights-delay/mlruns\n",
      "[CONFIG] MLflow experiment   : us_flights_delay\n",
      "[CONFIG] Target CLF          : high_delay_risk\n",
      "[CONFIG] Target REG          : avg_delay_per_flight\n",
      "[CONFIG] HIGH_DELAY_RATE_THRESHOLD : 0.25\n",
      "──────────────────────────\n",
      "[CONFIG] WEATHER_PROVIDER    : open-meteo\n",
      "[CONFIG] WEATHER_CACHE_DIR   : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\weather\n",
      "[CONFIG] WEATHER_CACHE_FILE  : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\weather\\weather_cache.json\n",
      "[CONFIG] WEATHER_DAILY_VARS  : ['temperature_2m_mean', 'precipitation_sum', 'windspeed_10m_max']\n",
      "──────────────────────────\n",
      "[CONFIG] API_HOST:PORT       : 0.0.0.0:8000\n",
      "[CONFIG] APP_HOST:PORT       : 0.0.0.0:8501\n",
      "──────────────────────────\n",
      "[INFO] train/val/test : (119998, 31) (25714, 31) (25714, 31)\n",
      "[INFO] Chargement du cache existant : C:\\Users\\Balerion\\Desktop\\us-flights-delay\\data\\processed\\airports_with_coords.csv\n",
      "[INFO] airports_df : (21370, 9)\n",
      "[INFO] flights_all : (171426, 32)\n",
      "[INFO] Combos (airport+year) : 3768\n",
      "[INFO] Cache météo total : 49690 entrées\n",
      "[INFO] flights_weather (brut) : (171426, 45)\n",
      "[INFO] Colonnes après normalisation : 35\n",
      "[CHECK] Toutes les features attendues sont présentes ✔\n",
      "[INFO] train_weather : (119998, 34)\n",
      "[INFO] val_weather   : (25714, 34)\n",
      "[INFO] test_weather  : (25714, 34)\n",
      "✔ 04_meteo_integration — VERSION FINALE ULTRA-STABLE\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# 04_meteo_integration — VERSION FINALE ULTRA-STABLE (PRO)\n",
    "# --------------------------------------------------------\n",
    "# - Intégration météo propre\n",
    "# - Merge robuste (aucune perte de colonnes)\n",
    "# - Normalisation colonnes : carrier / airport / names / year / month\n",
    "# - Nettoyage météo intermédiaire\n",
    "# - Contrôle strict : features == get_feature_columns()\n",
    "# - Sauvegarde train_weather / val_weather / test_weather\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT = Path.cwd().resolve().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(\"[INFO] ROOT =\", ROOT)\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import print_config_summary, DATA_PROCESSED_DIR\n",
    "from src.fetch_faa_airports import load_airports_with_coords\n",
    "from src.weather_api import build_weather_dataset\n",
    "from src.features import get_feature_columns\n",
    "\n",
    "print_config_summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# 1. Charger train / val / test\n",
    "\n",
    "# %%\n",
    "train = pd.read_csv(DATA_PROCESSED_DIR / \"train.csv\")\n",
    "val   = pd.read_csv(DATA_PROCESSED_DIR / \"val.csv\")\n",
    "test  = pd.read_csv(DATA_PROCESSED_DIR / \"test.csv\")\n",
    "\n",
    "print(\"[INFO] train/val/test :\", train.shape, val.shape, test.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# 2. Charger aéroports\n",
    "\n",
    "# %%\n",
    "airports_df = load_airports_with_coords()\n",
    "print(\"[INFO] airports_df :\", airports_df.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# 3. Concat + split\n",
    "\n",
    "# %%\n",
    "train_ = train.copy(); train_[\"split\"] = \"train\"\n",
    "val_   = val.copy();   val_[\"split\"] = \"val\"\n",
    "test_  = test.copy();  test_[\"split\"] = \"test\"\n",
    "\n",
    "flights_all = pd.concat([train_, val_, test_], ignore_index=True)\n",
    "print(\"[INFO] flights_all :\", flights_all.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# 4. Générer dataset météo COMPLET (12 mois d’un coup par airport/year)\n",
    "\n",
    "# %%\n",
    "flights_weather = build_weather_dataset(flights_all, airports_df)\n",
    "print(\"[INFO] flights_weather (brut) :\", flights_weather.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# 5. Normalisation colonnes — VERSION ROBUSTE\n",
    "\n",
    "# %%\n",
    "dfw = flights_weather.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 5.1 Restaurer colonnes _x/_y\n",
    "# -----------------------------\n",
    "renames = {\n",
    "    \"carrier_x\": \"carrier\",\n",
    "    \"carrier_name_x\": \"carrier_name\",\n",
    "    \"airport_x\": \"airport\",\n",
    "    \"airport_name_x\": \"airport_name\",\n",
    "    \"year_x\": \"year\",\n",
    "    \"month_x\": \"month\",\n",
    "}\n",
    "\n",
    "dfw = dfw.rename(columns={k: v for k, v in renames.items() if k in dfw.columns})\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"carrier_y\", \"carrier_name_y\",\n",
    "    \"airport_y\", \"airport_name_y\",\n",
    "    \"year_y\", \"month_y\",\n",
    "]\n",
    "\n",
    "dfw = dfw.drop(columns=[c for c in cols_to_drop if c in dfw.columns], errors=\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5.2 Harmonisation colonne month\n",
    "# -----------------------------\n",
    "if \"month\" not in dfw.columns:\n",
    "    raise ValueError(\"❌ ERREUR FATALE : month absente après normalisation météo\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5.3 Nettoyage colonnes météo intermédiaires\n",
    "# -----------------------------\n",
    "unused_meteo = [\n",
    "    \"temp_mean\", \"temp_min\", \"temp_max\",\n",
    "    \"precip_sum\", \"windspeed_max\",\n",
    "]\n",
    "dfw = dfw.drop(columns=[c for c in unused_meteo if c in dfw.columns], errors=\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5.4 Colonnes techniques inutiles\n",
    "# -----------------------------\n",
    "technical_cols = [\"faa_code\", \"lat\", \"lon\", \"key\"]\n",
    "dfw = dfw.drop(columns=[c for c in technical_cols if c in dfw.columns], errors=\"ignore\")\n",
    "\n",
    "print(\"[INFO] Colonnes après normalisation :\", len(dfw.columns))\n",
    "\n",
    "# %% [markdown]\n",
    "# 6. Vérification stricte features == get_feature_columns()\n",
    "\n",
    "# %%\n",
    "expected = set(get_feature_columns())\n",
    "cols_dfw = set(dfw.columns)\n",
    "\n",
    "missing = expected - cols_dfw\n",
    "extra   = cols_dfw - expected\n",
    "\n",
    "if missing:\n",
    "    raise ValueError(\n",
    "        f\"❌ Features manquantes : {missing}\\n\"\n",
    "        f\"▶ Vérifie build_weather_dataset ou normalisation\"\n",
    "    )\n",
    "\n",
    "print(\"[CHECK] Toutes les features attendues sont présentes ✔\")\n",
    "\n",
    "# %% [markdown]\n",
    "# 7. Re-split + save\n",
    "\n",
    "# %%\n",
    "if \"split\" not in dfw.columns:\n",
    "    raise ValueError(\"❌ Colonne 'split' absente !\")\n",
    "\n",
    "train_weather = dfw[dfw[\"split\"] == \"train\"].drop(columns=[\"split\"])\n",
    "val_weather   = dfw[dfw[\"split\"] == \"val\"].drop(columns=[\"split\"])\n",
    "test_weather  = dfw[dfw[\"split\"] == \"test\"].drop(columns=[\"split\"])\n",
    "\n",
    "print(\"[INFO] train_weather :\", train_weather.shape)\n",
    "print(\"[INFO] val_weather   :\", val_weather.shape)\n",
    "print(\"[INFO] test_weather  :\", test_weather.shape)\n",
    "\n",
    "train_weather.to_csv(DATA_PROCESSED_DIR / \"train_weather.csv\", index=False)\n",
    "val_weather.to_csv(DATA_PROCESSED_DIR / \"val_weather.csv\", index=False)\n",
    "test_weather.to_csv(DATA_PROCESSED_DIR / \"test_weather.csv\", index=False)\n",
    "\n",
    "print(\"✔ 04_meteo_integration — VERSION FINALE ULTRA-STABLE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
